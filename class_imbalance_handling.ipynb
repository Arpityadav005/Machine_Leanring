# ðŸ’¡ CLASS IMBALANCE HANDLING IN MACHINE LEARNING

# âœ… Class Imbalance: When one class significantly outnumbers the other(s)
# Example: In fraud detection, 98% transactions are normal (class 0), 2% are fraud (class 1)

# We will handle it using:
# 1. Upsampling
# 2. Downsampling
# 3. SMOTE (Synthetic Minority Oversampling Technique)

import pandas as pd
import numpy as np

# Fixing random seed for reproducibility
np.random.seed(1)

# -----------------------------
# Step 1: Creating an Imbalanced Dataset
# -----------------------------
no_samples = 1000
class_0_ratio = 0.9

# Majority class (90%)
no_class_0 = int(no_samples * class_0_ratio)
# Minority class (10%)
no_class_1 = 100

# Creating class 0 (majority)
class_0 = pd.DataFrame({
    'feature1': np.random.normal(0, 1, no_class_0),
    'feature2': np.random.normal(0, 1, no_class_0),
    'target': [0] * no_class_0
})

# Creating class 1 (minority)
class_1 = pd.DataFrame({
    'feature1': np.random.normal(3, 1, no_class_1),
    'feature2': np.random.normal(3, 1, no_class_1),
    'target': [1] * no_class_1
})

# Combining both classes
df = pd.concat([class_0, class_1]).reset_index(drop=True)

# Check class distribution
print(df.target.value_counts())

#...Upsampling the Minority Class
from sklearn.utils import resample

# Splitting the data
df_majority = df[df.target == 0]
df_minority = df[df.target == 1]

# Upsample minority class with replacement
df_minority_upsampled = resample(
    df_minority,
    replace=True,
    n_samples=len(df_majority),
    random_state=1
)

# Combine with majority class
df_upsampled = pd.concat([df_majority, df_minority_upsampled])

# Check new class balance
print(df_upsampled.target.value_counts())

# Downsample majority class without replacement
df_majority_downsampled = resample(
    df_majority,
    replace=False,
    n_samples=len(df_minority),
    random_state=1
)

# Combine with minority class
df_downsampled = pd.concat([df_minority, df_majority_downsampled])

# Check class balance after downsampling
print(df_downsampled.target.value_counts())

# Creating a synthetic classification dataset
from sklearn.datasets import make_classification

x, y = make_classification(
    n_samples=1000,
    n_features=2,
    n_redundant=0,
    n_clusters_per_class=1,
    weights=[0.9],  # 90% class 0
    random_state=42
)

# Plot the original imbalanced data
import matplotlib.pyplot as plt

df1 = pd.DataFrame(x, columns=['f1', 'f2'])
df2 = pd.DataFrame(y, columns=['target'])
final_df = pd.concat([df1, df2], axis=1)

plt.scatter(final_df['f1'], final_df['f2'], c=final_df['target'], cmap='coolwarm')
plt.title("Original Imbalanced Data")
plt.show()

# Install the imbalanced-learn package
# !pip install imbalanced-learn  # Uncomment if not installed

from imblearn.over_sampling import SMOTE

# Apply SMOTE
oversample = SMOTE(random_state=1)
x_smote, y_smote = oversample.fit_resample(final_df[['f1', 'f2']], final_df['target'])

# Visualizing SMOTE result
smote_df = pd.DataFrame(x_smote, columns=['f1', 'f2'])
smote_df['target'] = y_smote

plt.scatter(smote_df['f1'], smote_df['f2'], c=smote_df['target'], cmap='coolwarm')
plt.title("After Applying SMOTE")
plt.show()

print(smote_df['target'].value_counts())

